Well-defined problems and solutions(page 67)

uninformed search strategies

TREE -SEARCH(page 77) 
GRAPH -SEARCH(page 77)
BREADTH -FIRST -SEARCH(page 82)
UNIFORM -COST -SEARCH(page 84) : use path cost(the sum total of every fragment, expand every child of current node to get the path cost and then select the lowest-cost path,compared with not only the paths expanded in this round but also all the paths in the problem, for next expanding) instead of the path cost  known in adavance
Depth-first search(page 86)
Depth-limited search(page 88)
Iterative deepening search(page 89)
Bidirectional search(page 91)

Comparing uninformed search strategies(page 91)


informed(heuristic) search strategies - heuristic function h(n)

Greedy best-first search(page 93) : f(n) = h(n) , use straight-line distance as heuristic 
A* search(page 94) : f (n) = g(n) + h(n) , g implies the cost to reach the node n, h implies the cost to reach the destination strating from the node n.
Since g(n) gives the path cost from the start node to node n, and h(n) is the estimated cost of the cheapest path from n to the goal, we have
f (n) = estimated cost of the cheapest solution through n .The algorithm is identical to U NIFORM -C OST -S EARCH except that A ∗ uses g + h instead of g. drawback is it always runs out of space because it keeps track of all nodes explored

Conditions for optimality: Admissibility and consistency(page 94)

Admissibility : The first condition we require for optimality is that h(n) be an admissible heuristic. An admissible heuristic is one that never overestimates the cost to reach the goal. Because g(n) is the actual cost to reach n along the current path, and f (n) = g(n) + h(n), we have as an immediate consequence that f (n) never overestimates the true cost of a solution along the current path through n.

consistency : A second, slightly stronger condition called consistency (or sometimes monotonicity) is required only for applications of A ∗ to graph search. 9 A heuristic h(n) is consistent if, for every node n and every successor n of n generated by any action a, the estimated cost of reaching the goal from n is no greater than the step cost of getting to n plus the estimated cost of reaching the goal from n :
h(n) ≤ c(n, a, n') + h(n') .

Optimality of A*(page 95) 

Recursive best-first search (RBFS)(page 100)
effective branching factor(page 103)

Uninformed search methods have access only to the problem definition. The basic
algorithms are as follows:
– Breadth-first search expands the shallowest nodes first; it is complete, optimal
for unit step costs, but has exponential space complexity.
– Uniform-cost search expands the node with lowest path cost, g(n), and is optimal
for general step costs.
– Depth-first search expands the deepest unexpanded node first. It is neither com-
plete nor optimal, but has linear space complexity. Depth-limited search adds a
depth bound.
– Iterative deepening search calls depth-first search with increasing depth limits
until a goal is found. It is complete, optimal for unit step costs, has time complexity
comparable to breadth-first search, and has linear space complexity.
– Bidirectional search can enormously reduce time complexity, but it is not always
applicable and may require too much space.
• Informed search methods may have access to a heuristic function h(n) that estimates
the cost of a solution from n.
– The generic best-first search algorithm selects a node for expansion according to
an evaluation function.
– Greedy best-first search expands nodes with minimal h(n). It is not optimal but
is often efficient.
– A ∗ search expands nodes with minimal f (n) = g(n) + h(n). A ∗ is complete and
optimal, provided that h(n) is admissible (for T REE -S EARCH ) or consistent (for
G RAPH -S EARCH ). The space complexity of A ∗ is still prohibitive.
– RBFS (recursive best-first search) and SMA ∗ (simplified memory-bounded A ∗ )
are robust, optimal search algorithms that use limited amounts of memory; given
enough time, they can solve problems that A ∗ cannot solve because it runs out of
memory.



Local search
sideways move : to avoid shoulder
limit on the number of consecutive sideways moves : to avoid infinite loop at flat local maximum Stochastic hill climbing : chooses at random from among the uphill moves; the probability of selection can vary with the steepness of the uphill move. This usually converges more slowly than steepest ascent, but in some state landscapes, it finds better solutions.
First-choice hill climbing : implements stochastic hill climbing by generating successors randomly until one is generated that is better than the current state. This is a good strategy when a state has many (e.g., thousands) of successors.
Random-restart hill climbing : It conducts a series of hill-climbing searches from randomly generated initial states, until a goal is found. If each hill-climbing search has a probability p of success, then the expected number of restarts required is 1/p

A hill-climbing algorithm that never makes “downhill” moves toward states with lower value (or higher cost) is guaranteed to be incomplete, because it can get stuck on a local maximum. In contrast, a purely random walk—that is, moving to a successor chosen uniformly at random from the set of successors—is complete but extremely inefficient. Therefore, it seems reasonable to try to combine hill climbing with a random walk in some way that yields both efficiency and completeness